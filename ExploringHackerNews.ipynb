{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "This project will focus on analyzing the data set focused on submissions to a popular technology site Hacker News. \n",
    "\n",
    "We are interested in posts whose titles begin with either Ask HN or Show HN. We'll compare these two types of posts to determine:\n",
    "1. Which one receives more comments on average\n",
    "2. Do posts created at a specific time receive more comments on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the data set from Kaggle called hacker_news.csv. \n",
    "It has post from previous 12 months (September 2015 to September 2016). \n",
    "\n",
    "## Part 1\n",
    "\n",
    "Firstly, let's start by importing the modules and opening the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv', encoding='utf8')\n",
    "read_file=reader(opened_file)\n",
    "hn=list(read_file)\n",
    "headers=hn[0]\n",
    "hn=hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at header of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are seven columns:\n",
    "1. id: The unique identifier from Hacker News for the post\n",
    "2. title: The title of the post\n",
    "3. url: The URL that the posts links to, if the post has a URL\n",
    "4. num_points: The number of points the post acquired, calculated as the total \n",
    "5. num_comments: The number of comments that were made on the post\n",
    "6. author: The username of the person who submitted the post\n",
    "7. created_at: The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore first few rows of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this data set contains over 20,000 posts. Since we are interested in posts that start with Ask HN and Show HN, we would like to devide this data set into three separate lists. \n",
    "\n",
    "To do this, we'll loop through entire data set and filter using string method `string.startswith()` \n",
    "\n",
    "In our loop, we'll separete posts into three lists: `ask_posts`, `show_posts`, and `other_posts`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[]\n",
    "\n",
    "for row in hn:\n",
    "    title=row[1]\n",
    "    title=title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this worked corectly by exploring few rows from each new list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']]\n",
      "\n",
      "\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']]\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:2])\n",
    "print('\\n')\n",
    "print(show_posts[:2])\n",
    "print('\\n')\n",
    "print(other_posts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything was filtered correctly. Now let's check the number of posts in each list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "\n",
      "\n",
      "1162\n",
      "\n",
      "\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "print(len(ask_posts))\n",
    "print('\\n')\n",
    "print(len(show_posts))\n",
    "print('\\n')\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are substantially more 'other' posts than Ask HN and Show HN posts. \n",
    "\n",
    "A good step forward will be to check the difference between total amount of comments for Ask HN vs Show HN posts. Let's assign total amount of comments for Ask HN post to an integer `total_ask_posts` while Show HN posts to `total_show_posts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments on Show posts is 10.32\n",
      "Average number of comments on Ask posts is 14.04\n"
     ]
    }
   ],
   "source": [
    "#Code to calculate average amount of comments for Ask HN posts\n",
    "total_ask_posts=0\n",
    "avg_ask_posts=0\n",
    "\n",
    "\n",
    "for row in ask_posts:\n",
    "    n_com=int(row[4])\n",
    "    total_ask_posts+=n_com\n",
    "avg_ask_posts=total_ask_posts/len(ask_posts)\n",
    "\n",
    "#Code to calculate average amount of comments for Show HN posts\n",
    "total_show_posts=0\n",
    "avg_show_posts=0\n",
    "\n",
    "for row in show_posts:\n",
    "    n_com=int(row[4])\n",
    "    total_show_posts+=n_com\n",
    "avg_show_posts=total_show_posts/len(show_posts)\n",
    "print('Average number of comments on Show posts is {:.2f}'.format(avg_show_posts))\n",
    "print('Average number of comments on Ask posts is {:.2f}'.format(avg_ask_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that Ask posts on average generate higher amount of comments comparing to Show posts. This makes sense because by definition Ask posts 'ask' other users for an answer to a question. On the other side, Show posts don't ask other users for responce - they are strictly to display some information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Let's concentrate our focus on Ask HN posts. We would like to determine if there is a corelationship between what time a post was posted and amount of comments received. \n",
    "\n",
    "Because we will be working with time, we first need to import datetime module. We will then create a new list that will hold two columns: time of day(hour) and number of comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list=[]\n",
    "date_format='%m/%d/%Y %H:%M'\n",
    "for row in ask_posts:\n",
    "    created_at=row[6]\n",
    "#     line below first uses strptime to format string into datetime format\n",
    "#     and then uses strftime to select hour only.\n",
    "    created_at=dt.datetime.strptime(created_at, date_format).strftime(\"%H\")\n",
    "    n_com=int(row[4])\n",
    "    result_list.append([created_at, n_com])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at first few elements from the new table, we can see that this worked well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 6], ['13', 29], ['10', 1], ['14', 3], ['16', 17]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's created a frequency table that will have a distribution of hours and number of comments at that hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_hour={}\n",
    "comments_by_hour={}\n",
    "\n",
    "for row in result_list:\n",
    "    n_hour=row[0]\n",
    "    n_com=int(row[1])\n",
    "    if n_hour in counts_by_hour:\n",
    "        counts_by_hour[n_hour]+=1\n",
    "        comments_by_hour[n_hour]+=n_com\n",
    "    else:\n",
    "        counts_by_hour[n_hour]=1\n",
    "        comments_by_hour[n_hour]=n_com\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': 45,\n",
       " '13': 85,\n",
       " '10': 59,\n",
       " '14': 107,\n",
       " '16': 108,\n",
       " '23': 68,\n",
       " '12': 73,\n",
       " '17': 100,\n",
       " '15': 116,\n",
       " '21': 109,\n",
       " '20': 80,\n",
       " '02': 58,\n",
       " '18': 109,\n",
       " '03': 54,\n",
       " '05': 46,\n",
       " '19': 110,\n",
       " '01': 60,\n",
       " '22': 71,\n",
       " '08': 48,\n",
       " '04': 47,\n",
       " '00': 55,\n",
       " '06': 44,\n",
       " '07': 34,\n",
       " '11': 58}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_by_hour\n",
    "counts_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the average number of comments these posts received:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_hour=[]\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we now have the information that we were looking for, this format is difficult to read. Let's try to sort this list and make it easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour=[]\n",
    "for hr in avg_by_hour:\n",
    "    swap_avg_by_hour.append([hr[1],hr[0]])\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_swap=sorted(swap_avg_by_hour,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n",
      "13:00: 14.74 average comments per post\n",
      "10:00: 13.44 average comments per post\n",
      "14:00: 13.23 average comments per post\n",
      "18:00: 13.20 average comments per post\n",
      "17:00: 11.46 average comments per post\n",
      "01:00: 11.38 average comments per post\n",
      "11:00: 11.05 average comments per post\n",
      "19:00: 10.80 average comments per post\n",
      "08:00: 10.25 average comments per post\n",
      "05:00: 10.09 average comments per post\n",
      "12:00: 9.41 average comments per post\n",
      "06:00: 9.02 average comments per post\n",
      "00:00: 8.13 average comments per post\n",
      "23:00: 7.99 average comments per post\n",
      "07:00: 7.85 average comments per post\n",
      "03:00: 7.80 average comments per post\n",
      "04:00: 7.17 average comments per post\n",
      "22:00: 6.75 average comments per post\n",
      "09:00: 5.58 average comments per post\n"
     ]
    }
   ],
   "source": [
    "for each in sorted_swap:\n",
    "    print(\"{hr}:00: {avg:.2f} average comments per post\".format(hr=each[1], avg=each[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the information above, we can conclude that the best time to create a post on HN is during the 3PM hour(Eastern Time) or 2PM hour Central Time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Based on our analysis, to maximize the amount of comments a post received, we'd recommend to create a post between 3PM and 4PM (eastern time)\n",
    "However, since this data set does not include posts that did not receive comments, it is more accurate to say that of the posts that did receive comments, ask posts received more comments during 15:00 and 16:00. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
